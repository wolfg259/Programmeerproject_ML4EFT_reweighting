# Assessment of *Reweighting in ML4EFT*
- Er is door mij voor dit project best wat meer code geschreven dan er uiteindelijk in de repository branch te zien is. Een groot deel van het project zelf was ook het juist verkrijgen van de observable en weight data uit "raw" Les Houches Event files, het computationeel bepalen van truth values for benchmark tests, het juist herschalen van de verkregen data, etc. Om dit toch te kunnen laten zien, maar ook om het uiteindelijke resultaat van het project van begin tot eind te kunnen visualiseren, heb ik een extra notebook gemaakt, genaamd 'sample_pipeline.ipynb' in de main directory op de reweighting branch. Hierin laat ik zien wat er tussen het krijgen van gesimuleerde deeltjesfysica-data en het opleveren van een benchmark-plot moet gebeuren. De stappen die in dit notebook staan maken officieel geen deel uit van de implementatie van reweighting binnen ML4EFT, maar illustreren wel goed waar ik me in heb verdiept de afgelopen weken, dus ik zou jullie er toch graag op wijzen. Ik heb me hiervoor in een flink aantal wetenschappelijke python libraries als LHAPDF voor zogenoemde *parton distribution functions* en pylhe voor .lhe-verwerking verdiept, maar ook in deeltjesfysicasimulatiesoftware in C++ (zonder C++-ervaring) als [PYTHIA](https://www.pythia.org/), en ben zowel vanuit natuurkundig als programmeertechnisch oogpunt behoorlijk uit mijn comfortzone geweest.
- Een implementatie binnen 'classifier.py' waar ik best trots op ben is de penalty-term binnen de loss-functie. De andere contributors en ik kwamen namelijk het probleem tegen dat modellen soms buiten de fysisch mogelijke parabool in ($r$(ratio, modeloutput), $c$(Wilson-coefficientwaarde))-space kwamen, en soms bleef trainen. Dit kwam omdat de loss-functie zoals gedefiniëerd in de papers waar we mee werkten niet ongedefiniëerd was buiten deze parabool. Dit is alleen voor onze doeleinden niet interessant, omdat de oplossing waar we naar zoeken fysisch alleen kan bestaan binnen deze ruimte. Om er dus voor te zorgen dat de modellen altijd probeerden te convergeren binnen de fysisch mogelijke vlakken in parameter space, los van hoe de loss-functie daarbuiten gedefinieerd is, hebben we een soort "penalty"-term verzonnen. Er was namelijk op een (niet makkelijke) exacte manier te bepalen wanneer het model buiten dit fysische vlak zou vallen, namelijk als de discriminant van de parabool < 0, ofwel als geldt dat "nn_lin ** 2 - 4 * nn_quad > 0". Met een simpele ReLU-functie hebben we toen een "straf"-term in kunnen bouwen, die afhankelijk van hoe ver boven nul deze term lag een kwadratisch schalende extra term bij de loss optelde, om binnen de (loss, $r$, $c$)-ruimte een soort trechter te construeren die een onhandig trainend model terug naar fysisch mogelijke oplossingen leidt (regel 730 in core/classifier.py). Dit is simpel te visualiseren als ![schets penalty](penalty.png), waarbij de groene parabool de ruimte is waar we het model naartoe willen krijgen en de rode lijnen een schematische weergave van de penaly-term. Deze samenkomst van puur analytische, exacte, theoretische natuurkunde en implementaties van (ml-)concepten in python zijn ook eigenlijk waarom ik deze minor wilde gaan doen, dus dit was een noemenswaardige toevoeging.